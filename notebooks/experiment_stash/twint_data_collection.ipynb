{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint\n",
    "import os\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import logging\n",
    "import pandas as pd\n",
    "# logging.basicConfig(filename='twint_data_collection.log',level=logging.DEBUG)\n",
    "# logging.debug('This message should go to the log file')\n",
    "# logging.warning('And this, too')\n",
    "pd.set_option('display.max_colwidth', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shakir_za\n",
      "iclr_conf\n",
      "richhickey\n",
      "johnplattml\n",
      "jbilmes\n",
      "CorinnaCortes\n",
      "rherbrich\n",
      "gxr\n",
      "AndrewYNg\n",
      "lawrennd\n",
      "smolix\n",
      "ylecun\n",
      "hannawallach\n",
      "karpathy\n",
      "mxlearn\n",
      "GoogleAI\n",
      "memming\n",
      "MSFTResearchCam\n",
      "bschoelkopf\n",
      "mikiobraun\n",
      "NandoDF\n",
      "MSFTResearch\n",
      "ogrisel\n",
      "andrewmccallum\n",
      "SebastianThrun\n",
      "driainmurray\n",
      "earnmyturns\n",
      "PASCALNetwork\n",
      "icmlconf\n",
      "sejnowski\n",
      "cnl_salk\n"
     ]
    }
   ],
   "source": [
    "# Configure\n",
    "c = twint.Config()\n",
    "c.Username = \"neuripsconf\"\n",
    "c.Store_object = True\n",
    "# c.User_full = True\n",
    "# Run\n",
    "twint.run.Following(c)\n",
    "follow_list = twint.output.follows_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(follow_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216939636 | Andrew Ng | @AndrewYNg | Private: 0 | Verified: 1 | Bio: Co-Founder of Coursera; Stanford CS adjunct faculty. Former head of Baidu AI Group/Google Brain. #ai #machinelearning, #deeplearning #MOOCs | Location: Palo Alto, CA | Url: http://www.andrewng.org | Joined: 17 Nov 2010 7:39 PM | Tweets: 1289 | Following: 466 | Followers: 513045 | Likes: 987 | Media: 236 | Avatar: https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_400x400.jpg\n",
      "AndrewYNg\n",
      "AndrewYNg\n",
      "{'id': 216939636, 'name': 'Andrew Ng', 'username': 'AndrewYNg', 'bio': 'Co-Founder of Coursera; Stanford CS adjunct faculty. Former head of Baidu AI Group/Google Brain. #ai #machinelearning, #deeplearning #MOOCs', 'location': 'Palo Alto, CA', 'url': 'http://www.andrewng.org', 'join_date': '17 Nov 2010', 'join_time': '7:39 PM', 'tweets': 1289, 'following': 466, 'followers': 513045, 'likes': 987, 'media': 236, 'private': 0, 'verified': 1, 'profile_image_url': 'https://pbs.twimg.com/profile_images/733174243714682880/oyG30NEH_400x400.jpg', 'background_image': 'https://pbs.twimg.com/profile_banners/216939636/1483126470/1500x500'}\n",
      "48008938 | Yann LeCun | @ylecun | Private: 0 | Verified: 0 | Bio: Professor at NYU. Chief AI Scientist at Facebook. Researcher in AI, Machine Learning, etc. ACM Turing Award Laureate. | Location: New York | Url: http://yann.lecun.com | Joined: 17 Jun 2009 9:05 AM | Tweets: 5376 | Following: 288 | Followers: 211636 | Likes: 4282 | Media: 39 | Avatar: https://pbs.twimg.com/profile_images/2387565623/7gew8nz1z7ik1ch148so_400x400.jpeg\n",
      "ylecun\n",
      "ylecun\n",
      "{'id': 48008938, 'name': 'Yann LeCun', 'username': 'ylecun', 'bio': 'Professor at NYU. Chief AI Scientist at Facebook. Researcher in AI, Machine Learning, etc. ACM Turing Award Laureate.', 'location': 'New York', 'url': 'http://yann.lecun.com', 'join_date': '17 Jun 2009', 'join_time': '9:05 AM', 'tweets': 5376, 'following': 288, 'followers': 211636, 'likes': 4282, 'media': 39, 'private': 0, 'verified': 0, 'profile_image_url': 'https://pbs.twimg.com/profile_images/2387565623/7gew8nz1z7ik1ch148so_400x400.jpeg', 'background_image': None}\n",
      "387156826 | ICML Conference | @icmlconf | Private: 0 | Verified: 0 | Bio: International Conference on Machine Learning • July 12-18, 2020 (virtual) • #icml2020 • Contact: http://icml.cc/Help/Contact  | Location:  | Url: http://icml.cc/ | Joined: 8 Oct 2011 8:28 AM | Tweets: 941 | Following: 6 | Followers: 33188 | Likes: 886 | Media: 12 | Avatar: https://pbs.twimg.com/profile_images/1264614967908552704/ea0u5NgU_400x400.jpg\n",
      "icmlconf\n",
      "icmlconf\n",
      "{'id': 387156826, 'name': 'ICML Conference', 'username': 'icmlconf', 'bio': 'International Conference on Machine Learning • July 12-18, 2020 (virtual) • #icml2020 • Contact: http://icml.cc/Help/Contact\\xa0', 'location': '', 'url': 'http://icml.cc/', 'join_date': '8 Oct 2011', 'join_time': '8:28 AM', 'tweets': 941, 'following': 6, 'followers': 33188, 'likes': 886, 'media': 12, 'private': 0, 'verified': 0, 'profile_image_url': 'https://pbs.twimg.com/profile_images/1264614967908552704/ea0u5NgU_400x400.jpg', 'background_image': 'https://pbs.twimg.com/profile_banners/387156826/1514158533/1500x500'}\n"
     ]
    }
   ],
   "source": [
    "# for i in [\"AndrewYNg\", \"ylecun\", \"icmlconf\"]:\n",
    "\n",
    "all_users_info_dict = []\n",
    "def get_user_info(username):\n",
    "    c = twint.Config()\n",
    "    c.Username = str(username)\n",
    "    c.Store_object = True\n",
    "    twint.run.Lookup(c)\n",
    "    users = twint.output.users_list[-1]\n",
    "    print(i)\n",
    "    print(users.username)\n",
    "    user_info_dict = twint.storage.write_meta.userData(users)\n",
    "    print(user_info_dict)\n",
    "    all_users_info_dict.append(user_info_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Co-Founder of Coursera; Stanford CS adjunct faculty. Former head of Baidu AI Group/Google Brain. #ai #machinelearning, #deeplearning #MOOCs'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48008938 | Yann LeCun | @ylecun | Private: 0 | Verified: 0 | Bio: Professor at NYU. Chief AI Scientist at Facebook. Researcher in AI, Machine Learning, etc. ACM Turing Award Laureate. | Location: New York | Url: http://yann.lecun.com | Joined: 17 Jun 2009 9:05 AM | Tweets: 5372 | Following: 284 | Followers: 211067 | Likes: 4275 | Media: 39 | Avatar: https://pbs.twimg.com/profile_images/2387565623/7gew8nz1z7ik1ch148so_400x400.jpeg\n"
     ]
    }
   ],
   "source": [
    "c.Username = \"ylecun\"\n",
    "c.Store_object = True\n",
    "\n",
    "twint.run.Lookup(c)\n",
    "users = twint.output.users_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Andrew Ng'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_list = twint.output.follows_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(follow_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_KEYWORDS = [\"ai\", \"ml\", \"artificial intelligence\", \"machine learning\", \"deeplearning\", \"machinelearning\", \"nlproc\", \"nlp\", \"computer vision\", \"computervision\", \"cv\", \" reinforcement learning\", \"rl\", \"kaggle\", \"datascience\", \"google brain\", \"deepmind\", \"googleai\"]  \n",
    "\n",
    "\n",
    "test = \"\"\n",
    "\n",
    "if any(word in str(test).lower() for word in ML_KEYWORDS):\n",
    "    print (\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_user = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint\n",
    "import os\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import logging\n",
    "logging.basicConfig(filename='twint_data_collection.log',level=logging.DEBUG)\n",
    "\n",
    "def is_relevant_user(user):\n",
    "    twint.output.clean_lists()\n",
    "    c = twint.Config()\n",
    "    c.Username = str(user)\n",
    "    c.Store_object = True\n",
    "\n",
    "    twint.run.Lookup(c)\n",
    "#     print (twint.output.users_list)\n",
    "    user = twint.output.users_list[0]\n",
    "    print (user.name)\n",
    "    if any(word in str(user.bio).lower() for word in ML_KEYWORDS):\n",
    "        return True, user\n",
    "    else:\n",
    "        return False, None\n",
    "\n",
    "def main():\n",
    "    relevant_user.append(\"neuripsconf\")\n",
    "\n",
    "    for target in relevant_user:\n",
    "    #     logging.info('target user: ', target,\" ====> Starting to find followings  <====\")\n",
    "        # Configure\n",
    "        c = twint.Config()\n",
    "        c.Username = str(target)\n",
    "        c.Store_object = True\n",
    "        # Run\n",
    "        twint.run.Following(c)\n",
    "        follow_list = twint.output.follows_list\n",
    "    #     logging.info(\"====> Starting to find relevant users <====\")    \n",
    "        for user in follow_list:\n",
    "            rel, rel_user_info = is_relevant_user(user)\n",
    "            if rel:\n",
    "                if user not in relevant_user:\n",
    "                    relevant_user.append(user)\n",
    "    #                 logging.info (\"==> User :\" + str(user) + \" added!\")\n",
    "\n",
    "                    if len(relevant_user) % 100 == 0:\n",
    "    #                     logging.info (\"====> Starting to find write to files <====\") \n",
    "\n",
    "                        with open('relevant_user.txt', 'w') as f:\n",
    "                            for item in relevant_user:\n",
    "                                f.write(\"%s\\n\" % item)\n",
    "    #                     logging.info(\"====> Completed Writting to file! <====\")\n",
    "    #             else:\n",
    "    #                 logging.info(\"==> User :\" + str(user) + \" already present in the list!\")\n",
    "    #         else:\n",
    "    #             logging.info(\"==> User :\" + str(user) + \" not added!\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint\n",
    "import os\n",
    "import nest_asyncio\n",
    "import logging\n",
    "import json\n",
    "import pandas as pd\n",
    "nest_asyncio.apply()\n",
    "\n",
    "logging.basicConfig(filename=\"twint_data_collection.log\", level=logging.DEBUG)\n",
    "\n",
    "ML_KEYWORDS = [\n",
    "            \"ai \",\n",
    "            \"ml \",\n",
    "            \".ai\" \"fast.ai\" \"artificial intelligence\",\n",
    "            \"machine learning\",\n",
    "            \"deeplearning\",\n",
    "            \"machinelearning\",\n",
    "            \"nlproc\",\n",
    "            \"nlp \",\n",
    "            \"computer vision\",\n",
    "            \"computervision\",\n",
    "            \"cv \",\n",
    "            \"reinforcement learning\",\n",
    "            \"rl \",\n",
    "            \"kaggle\",\n",
    "            \"datascience\",\n",
    "            \"data science\",\n",
    "            \"google brain\",\n",
    "            \"deepmind\",\n",
    "            \"googleai\",\n",
    "            \"data scientist\",\n",
    "            \"pattern analysis\",\n",
    "            \"statistical modelling\",\n",
    "            \"computational learning\",\n",
    "            \"natural language processing\",\n",
    "            \"vision and learning\",\n",
    "            \"data visualization\",\n",
    "            \"matplotlib\",\n",
    "            \"computer science\",\n",
    "            \"data ethics\",\n",
    "            \"stats \",\n",
    "            \"deepmind\",\n",
    "            \"intelligent systems\",\n",
    "            \"a.i.\",\n",
    "            \"pytorch\",\n",
    "            \"tensorflow\",\n",
    "            \"keras\",\n",
    "            \"theano\",\n",
    "            \"bayesian statistics\",\n",
    "            \"openai\",\n",
    "            \"forecasting\"\n",
    "        ]\n",
    "\n",
    "\n",
    "def write_to_file(relevant_user, ):\n",
    "    if len(relevant_user) % 10 == 0:\n",
    "        with open(\"relevant_user.txt\", \"w+\") as f:\n",
    "            for item in relevant_user:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "                \n",
    "def write_user_info(relevant_user_info_list):\n",
    "    if len(relevant_user_info_list) > 100:\n",
    "        relevant_user_info_df = pd.DataFrame(relevant_user_info_list)\n",
    "        main_csv = pd.read_csv(\"relevant_user_info.csv\")\n",
    "        main_csv.append(relevant_user_info_df, ignore_index=True)\n",
    "        main_csv.to_csv(\"relevant_user_info.csv\",index=False)\n",
    "        empty_list  = []\n",
    "        return empty_list\n",
    "    return relevant_user_info_list\n",
    "        \n",
    "def is_relevant_user(user):\n",
    "\n",
    "    \n",
    "    twint.output.clean_lists()\n",
    "    c = twint.Config()\n",
    "    c.Username = str(user)\n",
    "    c.Store_object = True\n",
    "#     c.Hide_output = True\n",
    "    twint.run.Lookup(c)\n",
    "    users_list = twint.output.users_list\n",
    "    user = twint.output.users_list[0]\n",
    "    user_info_dict = twint.storage.write_meta.userData(user)\n",
    "    \n",
    "    if any(word in str(user.bio).lower() for word in ML_KEYWORDS):\n",
    "        print ( \"====> \", user_info_dict)\n",
    "        return True, user_info_dict\n",
    "    else:\n",
    "        return False, None\n",
    "\n",
    "\n",
    "def main():\n",
    "    relevant_user = []\n",
    "    relevant_user_info_list = []\n",
    "    relevant_user.append(\"neuripsconf\")\n",
    "    \n",
    "    for target in relevant_user:\n",
    "        print(\"==> \", target)\n",
    "        c = twint.Config()\n",
    "        c.Username = str(target)\n",
    "#         c.Hide_output = True\n",
    "        c.Store_object = True\n",
    "        twint.run.Following(c)\n",
    "        follow_list = twint.output.follows_list\n",
    "        \n",
    "        for user in follow_list:\n",
    "            print(\"hi\")\n",
    "            rel, rel_user_info = is_relevant_user(user)\n",
    "            if rel:         \n",
    "                relevant_user_info_list.append(rel_user_info)\n",
    "                relevant_user_info_list = write_user_info(relevant_user_info_list)\n",
    "            if rel and user not in relevant_user:  \n",
    "                relevant_user.append(user)\n",
    "                write_to_file(relevant_user)\n",
    "                \n",
    "                \n",
    "        break\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "if True and True:\n",
    "    print (\"hi\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2550600458 | Francesco Poldi | @noneprivacy | Private: 0 | Verified: 0 | Bio: 👀👤  Experienced Open Source Intelligence developer, hunter and privacy advocate. | Location: Phantásien | Url:  | Joined: 6 Jun 2014 10:46 AM | Tweets: 6187 | Following: 1300 | Followers: 3339 | Likes: 8231 | Media: 300 | Avatar: https://pbs.twimg.com/profile_images/1224048725171023877/7jHVO_YW_400x400.jpg\n"
     ]
    }
   ],
   "source": [
    "c = twint.Config()\n",
    "c.Username = \"noneprivacy\"\n",
    "# c.Hide_output = True\n",
    "c.Pandas = True\n",
    "# c.Store_pandas = True\n",
    "c.Pandas_clean=True\n",
    "c.Store_object = True\n",
    "c.Limit= 20   \n",
    "twint.run.Lookup(c)\n",
    "\n",
    "followed = twint.storage.panda.User_df\n",
    "twint.storage.panda.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 18)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "followed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2550600458', 'Francesco Poldi', 'noneprivacy',\n",
       "        '👀👤  Experienced Open Source Intelligence developer, hunter and privacy advocate.',\n",
       "        '', '6 Jun 2014 10:46 AM', '6 Jun 2014', '10:46 AM', 6187,\n",
       "        'Phantásien', 1300, 3339, 8231, 300, 0, 0,\n",
       "        'https://pbs.twimg.com/profile_images/1224048725171023877/7jHVO_YW_400x400.jpg',\n",
       "        'https://pbs.twimg.com/profile_banners/2550600458/1574952460/1500x500']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "followed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2550600458 | Francesco Poldi | @noneprivacy | Private: 0 | Verified: 0 | Bio: 👀👤  Experienced Open Source Intelligence developer, hunter and privacy advocate. | Location: Phantásien | Url:  | Joined: 6 Jun 2014 10:46 AM | Tweets: 6187 | Following: 1300 | Followers: 3339 | Likes: 8231 | Media: 300 | Avatar: https://pbs.twimg.com/profile_images/1224048725171023877/7jHVO_YW_400x400.jpg\n"
     ]
    }
   ],
   "source": [
    "twint.output.clean_lists()\n",
    "c = twint.Config()\n",
    "\n",
    "c.Username = \"noneprivacy\"\n",
    "\n",
    "c.Store_object = True\n",
    "c.Hide_output = True\n",
    "\n",
    "c.Store_object = True\n",
    "twint.run.Lookup(c)\n",
    "users_list = twint.output.users_list\n",
    "user = twint.output.users_list[0]\n",
    "user_info_dict = twint.storage.write_meta.userData(user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_user_info_list = []\n",
    "relevant_user_info_list.append(user_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('relevant_user_info.json', 'w') as fout:\n",
    "    json.dump(relevant_user_info_list , fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_csv = pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "main_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('relevant_user.txt') as f:\n",
    "    lines = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines[24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1283862778290348034 2020-07-17 02:05:14 +0530 <NeurIPSConf> Wondering how the NeurIPS review process is going? New blog post from @RaiaHadsell @MarcRanzato @hsuantienlin : https://medium.com/@NeurIPSConf/reviewing-is-underway-a5532d4615ec …\n",
      "1283779502313811970 2020-07-16 20:34:19 +0530 <NeurIPSConf> Want to write about your research but avoid the hype? @AIhubOrg has some suggestions  https://aihub.org/wp-content/uploads/2020/01/Guidelines-for-promoting-your-AI-research.pdf …\n",
      "1283153889471205388 2020-07-15 03:08:21 +0530 <NeurIPSConf> @AIhubOrg is a place for research without the hype. Supported by NeurIPS, it's a great place to share and explore work!  https://aihub.org/contribute/ \n",
      "1281359035422388226 2020-07-10 04:16:15 +0530 <NeurIPSConf> NeurIPS is a supporter of @AIhubOrg, they're always looking for practitioners to write about research.  https://aihub.org/contribute/ \n",
      "1267874210682146816 2020-06-02 23:12:22 +0530 <NeurIPSConf> Important notice to all authors: the paper submission deadline has been extended by 48 hours. The new deadline is Friday June 5, 2020 at 1pm PDT  Find the official announcement here:  https://neurips.cc/Conferences/2020/DeadlineExtension …\n",
      "1260989820966506497 2020-05-14 23:16:16 +0530 <NeurIPSConf> Call for meetups! https://twitter.com/EmtiyazKhan/status/1260568561199788035 …\n",
      "1250525403187490818 2020-04-16 02:14:24 +0530 <NeurIPSConf> We're excited to welcome the @repro_challenge back for 2020!  Check out their plans for this year and all the amazing work they've done so far!  https://reproducibility-challenge.github.io/neurips2019/  https://twitter.com/repro_challenge/status/1248072072309420039 …\n",
      "1243662644520923136 2020-03-28 03:44:15 +0530 <NeurIPSConf> Check out the latest update from the NeurIPS 2020 program chairs, touching on: 1) the upcoming submission deadline 2) recruitment of SACs, ACs and reviewers 3) the new ethical review process 4) the new early rejection process: https://medium.com/@NeurIPSConf/updates-on-program-committee-desk-rejections-353adb8dc1ae …\n",
      "1230953304613515264 2020-02-22 02:01:52 +0530 <NeurIPSConf> If you would like to recommend or become a reviewer for NeurIPS 2020, please fill out the form linked below. Thanks! https://docs.google.com/forms/d/11N0OhXKn9wB428Qq7jP8XPctM_DoJ-8lT-5EIDn4Y0M/edit …\n",
      "1230242921250770946 2020-02-20 02:59:03 +0530 <NeurIPSConf> Now with Raia's correct handle: @RaiaHadsell\n",
      "1230239787769970689 2020-02-20 02:46:36 +0530 <NeurIPSConf> Call for Papers for NeurIPS 2020 is out:  https://neurips.cc/Conferences/2020/CallForPapers …  Learn more about what is new this year in this video:  https://www.youtube.com/watch?v=361h6lHZGDg …  Also checkout this blog post by the PCs, Marc'Aurelio Ranzato, Nina Balcan, @hsuantienlin and @raiahadsel : https://medium.com/@NeurIPSConf/getting-started-with-neurips-2020-e350f9b39c28 …\n",
      "1227978472963764224 2020-02-13 21:00:57 +0530 <NeurIPSConf> The NeurIPS 2019 proceedings are posted.   https://papers.nips.cc/book/advances-in-neural-information-processing-systems-32-2019 …\n",
      "1204482188101738497 2019-12-11 00:55:06 +0530 <NeurIPSConf> NeurIPS Live Streaming https://slideslive.com/neurips/ \n",
      "1191452357831225344 2019-11-05 01:59:12 +0530 <NeurIPSConf> Mobile friendly NeurIPS 2019 schedule:  https://nips.cc/Conferences/2019/Schedule …\n",
      "1191068131839528960 2019-11-04 00:32:26 +0530 <NeurIPSConf> The schedule is almost complete for NeurIPS 2019  https://neurips.cc/Conferences/2019/ScheduleMultitrack …\n",
      "1186357882557784070 2019-10-22 00:35:35 +0530 <NeurIPSConf> Announcing NeurIPS Meetups! https://medium.com/@NeurIPSConf/announcing-neurips-meetups-44b2385c67a2 …\n",
      "1184492430118096896 2019-10-16 21:02:56 +0530 <NeurIPSConf> NeurIPS 2019 Call for socials.   https://nips.cc/Conferences/2019/Socials … We are very happy to inaugurate social events at the coming NeurIPS 2019. Given the steadily increasing amount of attendees of NeurIPS, it's becoming more and more difficult to meet colleagues with similar interests ...\n",
      "1182459045233356800 2019-10-11 06:23:00 +0530 <NeurIPSConf> There will be a rejection letter, but we haven't yet finished giving out all the awards. There are over 1600 applications to process.\n",
      "1174440782301761538 2019-09-19 03:21:17 +0530 <NeurIPSConf> The demo submission deadline for NeurIPS 2019 is Sept. 19, 2019, 4:59 p.m. pacific time.\n",
      "1172239263909515264 2019-09-13 01:33:14 +0530 <NeurIPSConf> All authors on accepted papers at NeurIPS 2019 who want to attend should be registering now. Be sure to log into the website first, so it recognizes that you have an accepted paper. Authors only have access to reserved tickets until September 26th or 27th depending on timezone.\n"
     ]
    }
   ],
   "source": [
    "import twint\n",
    "\n",
    "c = twint.Config()\n",
    "\n",
    "c.Username = \"neuripsconf\"\n",
    "# c.Custom[\"tweet\"] = [\"id\"]\n",
    "# c.Custom[\"user\"] = [\"bio\"]\n",
    "c.Limit = 10\n",
    "c.Store_csv = True\n",
    "c.Output = \"neuripsconf.csv\"\n",
    "\n",
    "twint.run.Search(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mbackup_july_22\u001b[0m/         relevant_user.txt  user_info.json\n",
      "relevant_user_info.csv  \u001b[01;34mtweet_since_2019\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls ../twitter_thought_leader/data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.load(open(\"../twitter_thought_leader/data/raw/user_info.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6042"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>bio</th>\n",
       "      <th>location</th>\n",
       "      <th>url</th>\n",
       "      <th>join_date</th>\n",
       "      <th>join_time</th>\n",
       "      <th>tweets</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>likes</th>\n",
       "      <th>media</th>\n",
       "      <th>private</th>\n",
       "      <th>verified</th>\n",
       "      <th>profile_image_url</th>\n",
       "      <th>background_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21202851</td>\n",
       "      <td>Ian Dunt</td>\n",
       "      <td>IanDunt</td>\n",
       "      <td>Jumped-up baldy. Editor of http://Politics.co....</td>\n",
       "      <td>London</td>\n",
       "      <td>https://www.canburypress.com/products/how-to-b...</td>\n",
       "      <td>18 Feb 2009</td>\n",
       "      <td>6:58 AM</td>\n",
       "      <td>126398</td>\n",
       "      <td>3952</td>\n",
       "      <td>294713</td>\n",
       "      <td>67687</td>\n",
       "      <td>2751</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/101949582...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/21202851...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1236113082201456640</td>\n",
       "      <td>The Radical AI Podcast</td>\n",
       "      <td>RadicalAIPod</td>\n",
       "      <td>AI Ethics Podcast centering marginalized or ot...</td>\n",
       "      <td>Denver, Colorado</td>\n",
       "      <td>http://radicalai.org</td>\n",
       "      <td>6 Mar 2020</td>\n",
       "      <td>6:15 PM</td>\n",
       "      <td>433</td>\n",
       "      <td>893</td>\n",
       "      <td>2199</td>\n",
       "      <td>438</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/126493501...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/12361130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2595244026</td>\n",
       "      <td>Eliezer Yudkowsky</td>\n",
       "      <td>ESYudkowsky</td>\n",
       "      <td>Ours is the era of inadequate AI alignment the...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>29 Jun 2014</td>\n",
       "      <td>1:14 PM</td>\n",
       "      <td>6195</td>\n",
       "      <td>64</td>\n",
       "      <td>35929</td>\n",
       "      <td>3476</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/706642709...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/25952440...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>543919023</td>\n",
       "      <td>Martha White</td>\n",
       "      <td>white_martha</td>\n",
       "      <td>PhD Comp Sci student at the University of Albe...</td>\n",
       "      <td>Edmonton, Canada</td>\n",
       "      <td>http://www.marthawhite.ca</td>\n",
       "      <td>2 Apr 2012</td>\n",
       "      <td>5:13 PM</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>688</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/329413704...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2666790169</td>\n",
       "      <td>Project Drawdown</td>\n",
       "      <td>ProjectDrawdown</td>\n",
       "      <td>The world’s leading resource for climate solut...</td>\n",
       "      <td>International</td>\n",
       "      <td>http://drawdown.org</td>\n",
       "      <td>21 Jul 2014</td>\n",
       "      <td>11:29 AM</td>\n",
       "      <td>2627</td>\n",
       "      <td>458</td>\n",
       "      <td>33839</td>\n",
       "      <td>2921</td>\n",
       "      <td>490</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/843937707...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/26667901...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                    name         username  \\\n",
       "0             21202851                Ian Dunt          IanDunt   \n",
       "1  1236113082201456640  The Radical AI Podcast     RadicalAIPod   \n",
       "2           2595244026       Eliezer Yudkowsky      ESYudkowsky   \n",
       "3            543919023            Martha White     white_martha   \n",
       "4           2666790169        Project Drawdown  ProjectDrawdown   \n",
       "\n",
       "                                                 bio          location  \\\n",
       "0  Jumped-up baldy. Editor of http://Politics.co....            London   \n",
       "1  AI Ethics Podcast centering marginalized or ot...  Denver, Colorado   \n",
       "2  Ours is the era of inadequate AI alignment the...                     \n",
       "3  PhD Comp Sci student at the University of Albe...  Edmonton, Canada   \n",
       "4  The world’s leading resource for climate solut...     International   \n",
       "\n",
       "                                                 url    join_date join_time  \\\n",
       "0  https://www.canburypress.com/products/how-to-b...  18 Feb 2009   6:58 AM   \n",
       "1                               http://radicalai.org   6 Mar 2020   6:15 PM   \n",
       "2                                                     29 Jun 2014   1:14 PM   \n",
       "3                          http://www.marthawhite.ca   2 Apr 2012   5:13 PM   \n",
       "4                                http://drawdown.org  21 Jul 2014  11:29 AM   \n",
       "\n",
       "   tweets  following  followers  likes  media  private  verified  \\\n",
       "0  126398       3952     294713  67687   2751        0         1   \n",
       "1     433        893       2199    438     28        0         0   \n",
       "2    6195         64      35929   3476     38        0         1   \n",
       "3       6         52        688      0      0        0         0   \n",
       "4    2627        458      33839   2921    490        0         1   \n",
       "\n",
       "                                   profile_image_url  \\\n",
       "0  https://pbs.twimg.com/profile_images/101949582...   \n",
       "1  https://pbs.twimg.com/profile_images/126493501...   \n",
       "2  https://pbs.twimg.com/profile_images/706642709...   \n",
       "3  https://pbs.twimg.com/profile_images/329413704...   \n",
       "4  https://pbs.twimg.com/profile_images/843937707...   \n",
       "\n",
       "                                    background_image  \n",
       "0  https://pbs.twimg.com/profile_banners/21202851...  \n",
       "1  https://pbs.twimg.com/profile_banners/12361130...  \n",
       "2  https://pbs.twimg.com/profile_banners/25952440...  \n",
       "3                                               None  \n",
       "4  https://pbs.twimg.com/profile_banners/26667901...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../twitter_thought_leader/data/raw/results_user_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/hustle/playground/twitter_thought_leader/data/raw/backup_july_22/tweets_1800+_users_1K_tweets_22_July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = \"/home/hustle/playground/twitter_thought_leader/data/raw/backup_july_22/tweets_1800+_users_1K_tweets_22_July/tweets\"\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "downloaded_user =  []\n",
    "for i in onlyfiles:\n",
    "    fname = i.split(\".\")[0]\n",
    "    downloaded_user.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1890"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(downloaded_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../twitter_thought_leader/data/raw/\"+ \"relevant_user.txt\") as f:\n",
    "    relevant_user = f.read().splitlines()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6023"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(relevant_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_user_b2 = list(set(relevant_user) - set(downloaded_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4133"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relevant_user_b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../twitter_thought_leader/data/raw/\"+  \"relevant_user_batch_2.txt\", \"w+\") as f:\n",
    "    for item in relevant_user_b2:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friend: shakir_za\n",
      "friend: iclr_conf\n",
      "friend: richhickey\n",
      "friend: johnplattml\n",
      "friend: jbilmes\n",
      "friend: CorinnaCortes\n",
      "friend: rherbrich\n",
      "friend: gxr\n",
      "friend: AndrewYNg\n",
      "friend: lawrennd\n",
      "friend: smolix\n",
      "friend: ylecun\n",
      "friend: hannawallach\n",
      "friend: karpathy\n",
      "friend: mxlearn\n",
      "friend: GoogleAI\n",
      "friend: memming\n",
      "friend: MSFTResearchCam\n",
      "friend: bschoelkopf\n",
      "friend: mikiobraun\n",
      "friend: NandoDF\n",
      "friend: MSFTResearch\n",
      "friend: ogrisel\n",
      "friend: andrewmccallum\n",
      "friend: SebastianThrun\n",
      "friend: driainmurray\n",
      "friend: earnmyturns\n",
      "friend: PASCALNetwork\n",
      "friend: icmlconf\n",
      "friend: sejnowski\n",
      "friend: cnl_salk\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import os\n",
    "\n",
    "def twitter_auth():\n",
    "    access_token = os.environ.get('TWITTER_ACCESS_KEY')\n",
    "    access_token_secret = os.environ.get('TWITTER_ACCESS_SECRET_KEY')\n",
    "    consumer_key = os.environ.get('TWITTER_API_KEY')\n",
    "    consumer_secret = os.environ.get('TWITTER_API_SECRET_KEY')\n",
    "\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "def collect_follower_using_twitter_api():\n",
    "    follow_dict = {}\n",
    "    with open(\"../twitter_thought_leader/data/raw/\"+ \"relevant_user.txt\") as f:\n",
    "        relevant_user = f.read().splitlines()   \n",
    "    for i in relevant_user:\n",
    "        follow_dict[str(i)] = tweepy.Cursor(api.friends, screen_name=\"neuripsconf\").items()\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 +2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../twitter_thought_leader/data/raw/relevant_user_info_complete.csv\",engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6050, 17)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_dup_df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5689, 17)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_dup_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Jumped-up baldy. Editor of http://Politics.co....\n",
       "1       AI Ethics Podcast centering marginalized or ot...\n",
       "2       Ours is the era of inadequate AI alignment the...\n",
       "3       PhD Comp Sci student at the University of Albe...\n",
       "4       The world’s leading resource for climate solut...\n",
       "                              ...                        \n",
       "6045    Britain economics correspondent, @TheEconomist...\n",
       "6046    Political correspondent @Daily_Record // @Reco...\n",
       "6047    AHRC CDA student @Oxfordhistory @nationaltrust...\n",
       "6048    🇿🇦🇬🇧 Immigrant. Also: radical interconnectedne...\n",
       "6049    Improvising.  'Lifelines, Notes on Life & Love...\n",
       "Name: bio, Length: 5689, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_dup_df[\"bio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_KEYWORDS =[\n",
    "            \"#ai\",\n",
    "            \" ai\",\n",
    "            \"ai \",\n",
    "            \"_ai\",\n",
    "            \"ai,\",\n",
    "            \"ai.\",\n",
    "            \"ai+\",\n",
    "            \"a.i.\",\n",
    "            \"#ml\",\n",
    "            \"ml.\",\n",
    "            \".ml\",\n",
    "            \"ml@\",\n",
    "            \"ml,\",\n",
    "            \"ml \",\n",
    "            \".ai\",\n",
    "            \"#rl\",\n",
    "            \" rl \",\n",
    "            \"#cv\",\n",
    "            \"cv \",\n",
    "            \"ai/\",\n",
    "            \"ml/\",\n",
    "            \"rl/\",\n",
    "            \"fast.ai\",\n",
    "            \"artificial intelligence\",\n",
    "            \"artificialintelligence\",\n",
    "            \"machine learn\",\n",
    "            \"machinelearning\",\n",
    "            \"deep learn\",\n",
    "            \"deeplearning\",\n",
    "            \"nlproc\",\n",
    "            \"nlp\",\n",
    "            \"stanfordnlp\",\n",
    "            \"stanfordai\",\n",
    "            \"stanfordailabs\",\n",
    "            \"data sci\",\n",
    "            \"computer vision\",\n",
    "            \"computervision\",\n",
    "            \"reinforcement learning\",\n",
    "            \"kaggle\",\n",
    "            \"datascience\",\n",
    "            \"data science\",\n",
    "            \"google brain\",\n",
    "            \"deepmind\",\n",
    "            \"deep mind\",\n",
    "            \"googleai\",\n",
    "            \"google ai\",\n",
    "            \"googlebrain\",\n",
    "            \"data scientist\",\n",
    "            \"pattern analysis\",\n",
    "            \"statistical modelling\",\n",
    "            \"computational learning\",\n",
    "            \"natural language processing\",\n",
    "            \"vision and learning\",\n",
    "            \"data visualization\",\n",
    "            \"matplotlib\",\n",
    "            \"computer science\",\n",
    "            \"data ethics\",\n",
    "            \"stats \",\n",
    "            \"autonomous cars\",\n",
    "            \"gan\",\n",
    "            \"openai\",\n",
    "            \"icml\",\n",
    "            \"neurips\",\n",
    "            \"intelligent systems\", \n",
    "            \"pytorch\",\n",
    "            \"tensorflow\",\n",
    "            \"keras\",\n",
    "            \"theano\",\n",
    "            \"bayesian statistics\",\n",
    "            \"openai\",\n",
    "            \"forecasting\",\n",
    "            \"iclr\"\n",
    "        ]\n",
    "\n",
    "test = \"\"\n",
    "\n",
    "if any(word in str(test).lower() for word in ML_KEYWORDS):\n",
    "    print (\"hi\")\n",
    "\n",
    "def is_relevant(test):\n",
    "    if any(word in str(test).lower() for word in ML_KEYWORDS):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/hustle/playground/twitter_thought_leader/data/raw/2nd_degree_relevant_user_info.csv\",engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50173, 17)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df = df[df[\"bio\"].apply(is_relevant)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df = rel_df.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4486, 17)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_rel_df = df[~df[\"bio\"].apply(is_relevant)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_rel_df = non_rel_df.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42898, 17)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_rel_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_rel_df.to_csv(\"/home/hustle/playground/twitter_thought_leader/data/raw/non_rel_user_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df = rel_df.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3128, 17)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df.to_csv(\"/home/hustle/playground/twitter_thought_leader/data/raw/2nd_degree_relevant_user_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "os.chdir(\"/home/hustle/playground/twitter_thought_leader/data/raw/follow_lists\")\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "\n",
    "all_filenames\n",
    "\n",
    "combined_csv = pd.concat([pd.read_csv(f, engine=\"python\") for f in all_filenames ])\n",
    "#export to csv\n",
    "\n",
    "combined_csv.shape\n",
    "\n",
    "combined_csv_rel_df = combined_csv[combined_csv[\"bio\"].apply(is_relevant)]\n",
    "\n",
    "non_rel_df = combined_csv[~combined_csv[\"bio\"].apply(is_relevant)]\n",
    "\n",
    "combined_csv_rel_df = combined_csv_rel_df.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv_rel_df.to_csv(\"/home/hustle/playground/twitter_thought_leader/data/raw/rel_user_info.csv\", mode=\"a\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_user_info = pd.read_csv(\"/home/hustle/playground/twitter_thought_leader/data/raw/rel_user_info.csv\",engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 17)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_user_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_rel_df = rel_user_info[rel_user_info[\"bio\"].apply(is_relevant)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6038, 17)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_rel_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_rel_df = combined_rel_df.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4748, 17)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_rel_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_rel_df.to_csv(\"/home/hustle/playground/twitter_thought_leader/data/raw/rel_user_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(combined_rel_df.username).to_csv(\"/home/hustle/playground/twitter_thought_leader/data/raw/4k_rel_user.txt\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/hustle/playground/twitter_thought_leader/data/raw/rel_user_info.csv\",engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df = df[df[\"bio\"].apply(is_relevant)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_rel_df = df[~df[\"bio\"].apply(is_relevant)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df.to_csv(\"/home/hustle/playground/twitter_thought_leader/data/raw/rel_user_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_rel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/hustle/playground/twitter_thought_leader/data/raw/\"+ \"refined_relevant_user_list.txt\") as f:\n",
    "    relevant_user = f.read().splitlines()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3706"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relevant_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3706"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(relevant_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(rel_df.username) - set(relevant_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_user = list(set(rel_df.username) - set(relevant_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(relevant_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.to_csv(\"/home/hustle/playground/twitter_thought_leader/data/raw/\"+ \"refined_relevant_user_list.txt\", mode='a', index=False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3230, 17)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_rel_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>bio</th>\n",
       "      <th>location</th>\n",
       "      <th>url</th>\n",
       "      <th>join_date</th>\n",
       "      <th>join_time</th>\n",
       "      <th>tweets</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>likes</th>\n",
       "      <th>media</th>\n",
       "      <th>private</th>\n",
       "      <th>verified</th>\n",
       "      <th>profile_image_url</th>\n",
       "      <th>background_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21202851</td>\n",
       "      <td>Ian Dunt</td>\n",
       "      <td>IanDunt</td>\n",
       "      <td>Jumped-up baldy. Editor of http://Politics.co....</td>\n",
       "      <td>London</td>\n",
       "      <td>https://www.canburypress.com/products/how-to-b...</td>\n",
       "      <td>18 Feb 2009</td>\n",
       "      <td>6:58 AM</td>\n",
       "      <td>126398.0</td>\n",
       "      <td>3952.0</td>\n",
       "      <td>294713.0</td>\n",
       "      <td>67687.0</td>\n",
       "      <td>2751</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/101949582...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/21202851...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2666790169</td>\n",
       "      <td>Project Drawdown</td>\n",
       "      <td>ProjectDrawdown</td>\n",
       "      <td>The world’s leading resource for climate solut...</td>\n",
       "      <td>International</td>\n",
       "      <td>http://drawdown.org</td>\n",
       "      <td>21 Jul 2014</td>\n",
       "      <td>11:29 AM</td>\n",
       "      <td>2627.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>33839.0</td>\n",
       "      <td>2921.0</td>\n",
       "      <td>490</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/843937707...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/26667901...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>266101459</td>\n",
       "      <td>Nadine White</td>\n",
       "      <td>Nadine_Writes</td>\n",
       "      <td>Award-winning journalist at @HuffPostUK | Past...</td>\n",
       "      <td>London, England</td>\n",
       "      <td>https://www.huffingtonpost.co.uk/author/nadine...</td>\n",
       "      <td>14 Mar 2011</td>\n",
       "      <td>10:17 AM</td>\n",
       "      <td>36214.0</td>\n",
       "      <td>4356.0</td>\n",
       "      <td>20340.0</td>\n",
       "      <td>15483.0</td>\n",
       "      <td>2299</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/128280439...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/26610145...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26826175</td>\n",
       "      <td>Tawana Petty</td>\n",
       "      <td>Combsthepoet</td>\n",
       "      <td>Data Justice director @DetCommTech, Co-Lead #O...</td>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>https://detroitcommunitytech.org</td>\n",
       "      <td>26 Mar 2009</td>\n",
       "      <td>12:26 PM</td>\n",
       "      <td>13399.0</td>\n",
       "      <td>3813.0</td>\n",
       "      <td>5258.0</td>\n",
       "      <td>8036.0</td>\n",
       "      <td>791</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/127994269...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/26826175...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>47647819</td>\n",
       "      <td>NICK COULDRY</td>\n",
       "      <td>couldrynick</td>\n",
       "      <td>teach media, comms, social theory at LSE. Main...</td>\n",
       "      <td>London UK</td>\n",
       "      <td>http://www.nickcouldry.org</td>\n",
       "      <td>16 Jun 2009</td>\n",
       "      <td>8:14 AM</td>\n",
       "      <td>2573.0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>9728.0</td>\n",
       "      <td>3118.0</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/685039688...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>70960617</td>\n",
       "      <td>Duncan Weldon</td>\n",
       "      <td>DuncanWeldon</td>\n",
       "      <td>Britain economics correspondent, @TheEconomist...</td>\n",
       "      <td>London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 Sep 2009</td>\n",
       "      <td>6:16 AM</td>\n",
       "      <td>75775.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>43869.0</td>\n",
       "      <td>64378.0</td>\n",
       "      <td>4469</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/117216200...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/70960617...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>239404265</td>\n",
       "      <td>Chris McCall</td>\n",
       "      <td>Dennynews</td>\n",
       "      <td>Political correspondent @Daily_Record // @Reco...</td>\n",
       "      <td>Glasgow, Scotland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17 Jan 2011</td>\n",
       "      <td>7:02 AM</td>\n",
       "      <td>18351.0</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>3833.0</td>\n",
       "      <td>16069.0</td>\n",
       "      <td>951</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/123019394...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/23940426...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>694807136946225152</td>\n",
       "      <td>Elisabeth Grass 🇪🇺</td>\n",
       "      <td>elisabeth_grass</td>\n",
       "      <td>AHRC CDA student @Oxfordhistory @nationaltrust...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://oxfordandempire.web.ox.ac.uk/people/el...</td>\n",
       "      <td>3 Feb 2016</td>\n",
       "      <td>12:58 AM</td>\n",
       "      <td>398.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>2381.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/128082837...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/69480713...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>64313</td>\n",
       "      <td>Basheera Khan</td>\n",
       "      <td>Bash</td>\n",
       "      <td>🇿🇦🇬🇧 Immigrant. Also: radical interconnectedne...</td>\n",
       "      <td>London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13 Dec 2006</td>\n",
       "      <td>9:24 AM</td>\n",
       "      <td>23355.0</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>3830.0</td>\n",
       "      <td>20276.0</td>\n",
       "      <td>557</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/378800000...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/64313/14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>67433765</td>\n",
       "      <td>Martin Wroe</td>\n",
       "      <td>MartinWroe</td>\n",
       "      <td>Improvising.  'Lifelines, Notes on Life &amp; Love...</td>\n",
       "      <td>London</td>\n",
       "      <td>http://martinwroe.com/</td>\n",
       "      <td>20 Aug 2009</td>\n",
       "      <td>2:44 PM</td>\n",
       "      <td>15082.0</td>\n",
       "      <td>2428.0</td>\n",
       "      <td>3518.0</td>\n",
       "      <td>4072.0</td>\n",
       "      <td>1161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/436151965...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3230 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                name         username  \\\n",
       "0               21202851            Ian Dunt          IanDunt   \n",
       "4             2666790169    Project Drawdown  ProjectDrawdown   \n",
       "6              266101459        Nadine White    Nadine_Writes   \n",
       "8               26826175        Tawana Petty     Combsthepoet   \n",
       "9               47647819        NICK COULDRY      couldrynick   \n",
       "...                  ...                 ...              ...   \n",
       "6045            70960617       Duncan Weldon     DuncanWeldon   \n",
       "6046           239404265        Chris McCall        Dennynews   \n",
       "6047  694807136946225152  Elisabeth Grass 🇪🇺  elisabeth_grass   \n",
       "6048               64313       Basheera Khan             Bash   \n",
       "6049            67433765         Martin Wroe       MartinWroe   \n",
       "\n",
       "                                                    bio           location  \\\n",
       "0     Jumped-up baldy. Editor of http://Politics.co....             London   \n",
       "4     The world’s leading resource for climate solut...      International   \n",
       "6     Award-winning journalist at @HuffPostUK | Past...    London, England   \n",
       "8     Data Justice director @DetCommTech, Co-Lead #O...        Detroit, MI   \n",
       "9     teach media, comms, social theory at LSE. Main...          London UK   \n",
       "...                                                 ...                ...   \n",
       "6045  Britain economics correspondent, @TheEconomist...             London   \n",
       "6046  Political correspondent @Daily_Record // @Reco...  Glasgow, Scotland   \n",
       "6047  AHRC CDA student @Oxfordhistory @nationaltrust...                NaN   \n",
       "6048  🇿🇦🇬🇧 Immigrant. Also: radical interconnectedne...             London   \n",
       "6049  Improvising.  'Lifelines, Notes on Life & Love...             London   \n",
       "\n",
       "                                                    url    join_date  \\\n",
       "0     https://www.canburypress.com/products/how-to-b...  18 Feb 2009   \n",
       "4                                   http://drawdown.org  21 Jul 2014   \n",
       "6     https://www.huffingtonpost.co.uk/author/nadine...  14 Mar 2011   \n",
       "8                      https://detroitcommunitytech.org  26 Mar 2009   \n",
       "9                            http://www.nickcouldry.org  16 Jun 2009   \n",
       "...                                                 ...          ...   \n",
       "6045                                                NaN   2 Sep 2009   \n",
       "6046                                                NaN  17 Jan 2011   \n",
       "6047  https://oxfordandempire.web.ox.ac.uk/people/el...   3 Feb 2016   \n",
       "6048                                                NaN  13 Dec 2006   \n",
       "6049                             http://martinwroe.com/  20 Aug 2009   \n",
       "\n",
       "     join_time    tweets  following  followers    likes media private  \\\n",
       "0      6:58 AM  126398.0     3952.0   294713.0  67687.0  2751       0   \n",
       "4     11:29 AM    2627.0      458.0    33839.0   2921.0   490       0   \n",
       "6     10:17 AM   36214.0     4356.0    20340.0  15483.0  2299       0   \n",
       "8     12:26 PM   13399.0     3813.0     5258.0   8036.0   791       0   \n",
       "9      8:14 AM    2573.0      795.0     9728.0   3118.0    74       0   \n",
       "...        ...       ...        ...        ...      ...   ...     ...   \n",
       "6045   6:16 AM   75775.0     3016.0    43869.0  64378.0  4469       0   \n",
       "6046   7:02 AM   18351.0     1498.0     3833.0  16069.0   951       0   \n",
       "6047  12:58 AM     398.0      807.0      595.0   2381.0    24       0   \n",
       "6048   9:24 AM   23355.0     1883.0     3830.0  20276.0   557       0   \n",
       "6049   2:44 PM   15082.0     2428.0     3518.0   4072.0  1161       0   \n",
       "\n",
       "      verified                                  profile_image_url  \\\n",
       "0          1.0  https://pbs.twimg.com/profile_images/101949582...   \n",
       "4          1.0  https://pbs.twimg.com/profile_images/843937707...   \n",
       "6          1.0  https://pbs.twimg.com/profile_images/128280439...   \n",
       "8          0.0  https://pbs.twimg.com/profile_images/127994269...   \n",
       "9          0.0  https://pbs.twimg.com/profile_images/685039688...   \n",
       "...        ...                                                ...   \n",
       "6045       1.0  https://pbs.twimg.com/profile_images/117216200...   \n",
       "6046       0.0  https://pbs.twimg.com/profile_images/123019394...   \n",
       "6047       0.0  https://pbs.twimg.com/profile_images/128082837...   \n",
       "6048       0.0  https://pbs.twimg.com/profile_images/378800000...   \n",
       "6049       0.0  https://pbs.twimg.com/profile_images/436151965...   \n",
       "\n",
       "                                       background_image  \n",
       "0     https://pbs.twimg.com/profile_banners/21202851...  \n",
       "4     https://pbs.twimg.com/profile_banners/26667901...  \n",
       "6     https://pbs.twimg.com/profile_banners/26610145...  \n",
       "8     https://pbs.twimg.com/profile_banners/26826175...  \n",
       "9                                                   NaN  \n",
       "...                                                 ...  \n",
       "6045  https://pbs.twimg.com/profile_banners/70960617...  \n",
       "6046  https://pbs.twimg.com/profile_banners/23940426...  \n",
       "6047  https://pbs.twimg.com/profile_banners/69480713...  \n",
       "6048  https://pbs.twimg.com/profile_banners/64313/14...  \n",
       "6049                                                NaN  \n",
       "\n",
       "[3230 rows x 17 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_rel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "def check_if_file_present(username):\n",
    "    mypath = '/home/hustle/playground/twitter_thought_leader/data/raw/follow_lists/'\n",
    "    onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "    downloaded_user =  []\n",
    "    for i in onlyfiles:\n",
    "        fname = i.split(\".\")[0]\n",
    "        downloaded_user.append(fname)\n",
    "        \n",
    "    if username in downloaded_user:\n",
    "        return \n",
    "    raise\n",
    "    \n",
    "def subprocess_cmd(command):\n",
    "    process = subprocess.Popen(command,stdout=subprocess.PIPE, shell=True)\n",
    "    proc_stdout = process.communicate()[0].strip()\n",
    "    print( proc_stdout)\n",
    "\n",
    "list_of_user = [ \"HEPfeickert\",\n",
    "\"ClementDelangue\",\n",
    "\"FedPernici\"]   \n",
    "def get_follow_list_with_retry(username):\n",
    "    count  = 0\n",
    "    while count < 5 :\n",
    "        print(\"attempt: \" + str(count) + \" for user: \" + username)\n",
    "        count = count + 1\n",
    "        try:\n",
    "            command = 'cd /home/hustle/playground/twitter_thought_leader/data/raw/follow_lists/; conda activate tp; twint -u ' + username + ' --following -o ' + username +  '.txt'\n",
    "            print(command)\n",
    "            subprocess_cmd(command)\n",
    "            \n",
    "            check_if_file_present(username)\n",
    "        except:\n",
    "            print (\"sleeping for 20 secs\")\n",
    "            time.sleep(20)\n",
    "            continue\n",
    "        print(\"Completed for user: \" + username)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list_of_user:\n",
    "    get_follow_list_with_retry(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "follow_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "follow_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "command = \"twint -u neuripsconf --following --user-full -o neuripsconf.csv --csv\"\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'total 1892\\n-rw-r--r-- 1 hustle hustle 228323 Jul 24 18:53 abhi1thakur.csv\\n-rw-r--r-- 1 hustle hustle 156706 Jul 24 18:19 A_K_Nain.csv\\n-rw-r--r-- 1 hustle hustle 227347 Jul 25 13:45 fchollet.csv\\n-rw-r--r-- 1 hustle hustle 102794 Jul 24 18:41 JayAlammar.csv\\n-rw-r--r-- 1 hustle hustle 257272 Jul 25 17:36 jeremyphoward.csv\\n-rw-r--r-- 1 hustle hustle 271475 Jul 24 17:09 PralayRamteke.csv\\n-rw-r--r-- 1 hustle hustle 655164 Jul 25 15:20 suzatweet.csv\\n'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "result = subprocess.run(['ls', '-l'], stdout=subprocess.PIPE)\n",
    "result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'shakir_za\\niclr_conf\\nrichhickey\\njohnplattml\\njbilmes\\nCorinnaCortes\\nrherbrich\\ngxr\\nAndrewYNg\\nlawrennd\\nsmolix\\nylecun\\nhannawallach\\nkarpathy\\nmxlearn\\nGoogleAI\\nmemming\\nMSFTResearchCam\\nbschoelkopf\\nmikiobraun\\nNandoDF\\nMSFTResearch\\nogrisel\\nandrewmccallum\\nSebastianThrun\\ndriainmurray\\nearnmyturns\\nPASCALNetwork\\nicmlconf\\nsejnowski\\ncnl_salk'\n"
     ]
    }
   ],
   "source": [
    "def subprocess_cmd(command):\n",
    "    process = subprocess.Popen(command,stdout=subprocess.PIPE, shell=True)\n",
    "    proc_stdout = process.communicate()[0].strip()\n",
    "    print( proc_stdout)\n",
    "\n",
    "subprocess_cmd('conda activate tp; twint -u neuripsconf --following -o neuripsconf.txt --csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "read_files = glob.glob(\"/home/hustle/playground/twitter_thought_leader/data/raw/test/*.txt\")\n",
    "\n",
    "with open(\"/home/hustle/playground/twitter_thought_leader/data/raw/selected_2nd_degree_result.txt\", \"wb\") as outfile:\n",
    "    for f in read_files:\n",
    "        with open(f, \"rb\") as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1560"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(read_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = pd.read_csv(\"/home/hustle/playground/twitter_thought_leader/data/raw/pandeyparul_relevant_user_info.csv\",engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              An interactive deep learning book with code, math, and discussions. Check out http://D2L.ai  and  http://github.com/d2l-ai/d2l-en/ \n",
       "1                                                                                                                                                              NaN\n",
       "2                                               Founder @dataquestio, where you can learn data science interactively online.  Worked at @edXOnline and @StateDept.\n",
       "3                                                                                                                             @womenwhocode Python Track Community\n",
       "4                                                                                                        3D Animator & Youtuber - I like learning how things work!\n",
       "                                                                                  ...                                                                             \n",
       "902                                                                                      Neuromorphic Computing, Machine Learning, AI & Memristors.  San Jose, CA.\n",
       "903                    Co-Founder of Coursera; Stanford CS adjunct faculty. Former head of Baidu AI Group/Google Brain. #ai #machinelearning, #deeplearning #MOOCs\n",
       "904                                                                                                                                   CEO of Microsoft Corporation\n",
       "905                        Apple CEO  Auburn 🏀 🏈 Duke 🏀 National Parks 🏞️ “Life's most persistent and urgent question is, 'What are you doing for others?'” - MLK\n",
       "906    #ArtificialIntelligence #MachineLearning #DeepLearning #fintech #Bigdata #Marketing #Robotics #IoT #DL #ML #tech #AI #HealthTech #Insurtech #5G Imtiaz Adam\n",
       "Name: bio, Length: 907, dtype: object"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fd.bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df = fd[fd[\"bio\"].apply(is_relevant)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(rel_df.username))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/hustle/playground/twitter_thought_leader/data/raw/\"+ \"4k_rel_user.txt\") as f:\n",
    "    relevant_user = f.read().splitlines()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034033"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/home/hustle/playground/twitter_thought_leader/data/raw/2nd_degree_follow_list.txt\") as f:\n",
    "    new_relevant_user = f.read().splitlines()   \n",
    "\n",
    "len(set(new_relevant_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_users = set(rel_df.username) - set(relevant_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(list(new_users))\n",
    "\n",
    "ser.to_csv(\"/home/hustle/playground/twitter_thought_leader/data/raw/\"+ \"4k_rel_user.txt\", mode='a', index=False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = list(set(rel_df.username) - set(relevant_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.to_csv(\"/home/hustle/playground/twitter_thought_leader/data/raw/\"+ \"refined_relevant_user_list.txt\", mode='a', index=False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/hustle/playground/twitter_thought_leader/data/raw/follow_lists/\"+ \"pandeyparul.txt\") as f:\n",
    "    pandeyparul_relevant_user = f.read().splitlines()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "908"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pandeyparul_relevant_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/hustle/playground/twitter_thought_leader/data/raw/\"+ \"4k_rel_user.txt\") as f:\n",
    "    relevant_user = f.read().splitlines()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = '/home/hustle/playground/twitter_thought_leader/data/raw/tweets_last_1500/'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "downloaded_user =  []\n",
    "for i in onlyfiles:\n",
    "    fname = i.split(\".\")[0]\n",
    "    downloaded_user.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4748"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relevant_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "681"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(pandeyparul_relevant_user) - set(downloaded_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_user_info = pd.read_csv(\"/home/hustle/playground/twitter_thought_leader/data/raw/rel_user_info.csv\",engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9115, 17)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_user_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_user_info = rel_user_info.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9115, 17)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_user_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_user_info_list = list(rel_user_info.username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RadicalAIPod',\n",
       " 'ESYudkowsky',\n",
       " 'white_martha',\n",
       " 'iraphas13',\n",
       " 'onucharlesc',\n",
       " 'karpathy',\n",
       " 'divy93t',\n",
       " 'alexhanna',\n",
       " 'BrownSarahM',\n",
       " 'radical_ai_']"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_user_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(pandeyparul_relevant_user) - set(rel_user_info_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = [\n",
    "#             \"/home/hustle/playground/twitter_thought_leader/data/raw/follow_lists/JayAlammar.txt\",\n",
    "#             \"/home/hustle/playground/twitter_thought_leader/data/raw/follow_lists/abhi1thakur.txt\",\n",
    "#             \"/home/hustle/playground/twitter_thought_leader/data/raw/follow_lists/suzatweet.txt\",\n",
    "#             \"/home/hustle/playground/twitter_thought_leader/data/raw/follow_lists/fchollet.txt\",\n",
    "#             \"/home/hustle/playground/twitter_thought_leader/data/raw/follow_lists/A_K_Nain.txt\",\n",
    "#             \"/home/hustle/playground/twitter_thought_leader/data/raw/follow_lists/NirantK.txt\",\n",
    "#             \"/home/hustle/playground/twitter_thought_leader/data/raw/follow_lists/omarsar0.txt\",\n",
    "            \"/home/hustle/playground/twitter_thought_leader/data/raw/follow_lists/lexfridman.txt\",\n",
    "            \"/home/hustle/playground/twitter_thought_leader/data/raw/follow_lists/bhutanisanyam1.txt\",\n",
    "            \"/home/hustle/playground/twitter_thought_leader/data/raw/follow_lists/drfeifei.txt\",\n",
    "#             \"/home/hustle/playground/twitter_thought_leader/data/raw/follow_lists/PralayRamteke.txt\",\n",
    "        ]\n",
    "\n",
    "\n",
    "import glob\n",
    "\n",
    "# read_files = glob.glob(\"/home/hustle/playground/twitter_thought_leader/data/raw/follow_lists/*.txt\")\n",
    "\n",
    "with open(\"/home/hustle/playground/twitter_thought_leader/data/raw/user_list_1_result.txt\", \"wb\") as outfile:\n",
    "    for f in user_list:\n",
    "        with open(f, \"rb\") as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/hustle/playground/twitter_thought_leader/data/raw/\"+ \"selected_2nd_degree_result.txt\") as f:\n",
    "    relevant_user = f.read().splitlines()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497100"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relevant_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301827"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(relevant_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abhi1thakur.csv',\n",
       " 'JayAlammar.csv',\n",
       " 'relevant_user_info_new.csv',\n",
       " 'suzatweet.csv',\n",
       " 'PralayRamteke.csv',\n",
       " 'HEPfeickert.csv',\n",
       " 'neuripsconf.csv',\n",
       " 'A_K_Nain.csv',\n",
       " 'fchollet.csv',\n",
       " 'jeremyphoward.csv']"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "os.chdir(\"/home/hustle/playground/twitter_thought_leader/data/raw/follow_lists\")\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "\n",
    "all_filenames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8005, 17)"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv = pd.concat([pd.read_csv(f, engine=\"python\") for f in all_filenames ])\n",
    "#export to csv\n",
    "\n",
    "combined_csv.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4177, 17)"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv_rel_df = combined_csv[combined_csv[\"bio\"].apply(is_relevant)]\n",
    "\n",
    "non_rel_df = combined_csv[~combined_csv[\"bio\"].apply(is_relevant)]\n",
    "\n",
    "combined_csv_rel_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_csv_rel_df = combined_csv_rel_df.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2911, 17)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv_rel_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AiWamri',\n",
       " 'AudeOliva',\n",
       " 'BalkirEsma',\n",
       " 'Data88Geek',\n",
       " 'FirasBaba96',\n",
       " 'GoogleBrain',\n",
       " 'IBMDataScience',\n",
       " 'KevinJDonaldson',\n",
       " 'PavelOstyakov',\n",
       " 'SumanRavuri',\n",
       " 'aadrake',\n",
       " 'bah2029',\n",
       " 'brunasmith',\n",
       " 'debuggermassa',\n",
       " 'dplrw',\n",
       " 'enqush',\n",
       " 'fairseq',\n",
       " 'jysohn23',\n",
       " 'marii18052483',\n",
       " 'sanjay128',\n",
       " 'viveksck',\n",
       " 'xhluu',\n",
       " 'zuzoovn'}"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(set(combined_csv_rel_df.username) -  set(downloaded_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = list(set(relevant_user) -  set(downloaded_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.to_csv(\"/home/hustle/playground/twitter_thought_leader/data/raw/\"+ \"selected_2nd_degree.txt\", index=False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/hustle/playground/twitter_thought_leader/data/interim/cleaned_tweets\")\n",
    "extension = 'txt'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "print(len(all_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tp] *",
   "language": "python",
   "name": "conda-env-tp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
